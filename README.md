# Setup Guide for Disorder-Diffusion Single-Pixel Imaging Research

## Quick Start

### Option 1: Using Conda (Recommended)

```bash
# Clone your repository (or create new project directory)
cd /path/to/disorder-diffusion

# Create environment from yml file
conda env create -f environment.yml

# Activate environment
conda activate disorder-diffusion

# Verify installation
python -c "import torch, diffusers, jax; print('All imports successful!')"

# Launch Jupyter Lab
jupyter lab
```

### Option 2: Using pip (Alternative)

```bash
# Create virtual environment
python3.11 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install requirements
pip install -r requirements.txt

# Verify installation
python -c "import torch, diffusers, jax; print('All imports successful!')"
```

---

## Project Structure

Create this directory structure for your research:

```
disorder-diffusion/
â”œâ”€â”€ environment.yml              # Conda environment specification
â”œâ”€â”€ requirements.txt             # Pip requirements
â”œâ”€â”€ setup.py                     # Package setup (if needed)
â”œâ”€â”€ README.md                    # Project overview
â”œâ”€â”€ .gitignore                   # Git ignore rules
â”‚
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ diffusion/               # Diffusion model code
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py              # Base DPS class
â”‚   â”‚   â”œâ”€â”€ dps.py               # Standard DPS
â”‚   â”‚   â”œâ”€â”€ da_dps.py            # Disorder-averaged DPS (Stage 1)
â”‚   â”‚   â”œâ”€â”€ ctrw_dps.py          # CTRW-based DPS (Stage 2)
â”‚   â”‚   â””â”€â”€ da_boed.py           # DA-BOED framework (Stage 3)
â”‚   â”‚
â”‚   â”œâ”€â”€ disorder/                # Disorder theory implementations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ema.py               # Effective Medium Approximation
â”‚   â”‚   â”œâ”€â”€ ctrw.py              # CTRW formalism
â”‚   â”‚   â”œâ”€â”€ anomalous.py         # Anomalous diffusion utilities
â”‚   â”‚   â””â”€â”€ green_functions.py   # Green function calculations
â”‚   â”‚
â”‚   â”œâ”€â”€ imaging/                 # Imaging-specific code
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ single_pixel.py      # Single-pixel imaging simulation
â”‚   â”‚   â”œâ”€â”€ measurement.py       # Measurement matrices (Gaussian, Hadamard, DMD)
â”‚   â”‚   â”œâ”€â”€ forward_models.py    # Forward imaging models
â”‚   â”‚   â””â”€â”€ noise_models.py      # Photon noise, readout noise
â”‚   â”‚
â”‚   â”œâ”€â”€ bayesian/                # Bayesian experimental design
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ eig.py               # Expected Information Gain computation
â”‚   â”‚   â”œâ”€â”€ pooled_posterior.py  # Pooled posterior sampling
â”‚   â”‚   â”œâ”€â”€ adaptive_design.py   # Adaptive measurement design
â”‚   â”‚   â””â”€â”€ optimization.py      # Design optimization algorithms
â”‚   â”‚
â”‚   â””â”€â”€ utils/                   # Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ metrics.py           # PSNR, SSIM, FID, LPIPS
â”‚       â”œâ”€â”€ plotting.py          # Visualization helpers
â”‚       â”œâ”€â”€ io.py                # Data I/O functions
â”‚       â”œâ”€â”€ config.py            # Configuration management
â”‚       â””â”€â”€ logging.py           # Logging utilities
â”‚
â”œâ”€â”€ experiments/                 # Experimental scripts
â”‚   â”œâ”€â”€ stage1/                  # Stage 1: DA-DPS
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ train_diffusion.py   # Train score network
â”‚   â”‚   â”œâ”€â”€ evaluate_dps.py      # Evaluate standard DPS
â”‚   â”‚   â”œâ”€â”€ evaluate_da_dps.py   # Evaluate disorder-averaged DPS
â”‚   â”‚   â”œâ”€â”€ compare_methods.py   # Comparison experiments
â”‚   â”‚   â””â”€â”€ config.yaml          # Experiment config
â”‚   â”‚
â”‚   â”œâ”€â”€ stage2/                  # Stage 2: CTRW-DPS
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ optimal_alpha.py     # Compute optimal Î±
â”‚   â”‚   â”œâ”€â”€ ctrw_scheduling.py   # Test CTRW schedules
â”‚   â”‚   â”œâ”€â”€ convergence_analysis.py  # Convergence rate experiments
â”‚   â”‚   â”œâ”€â”€ ablation_study.py    # Ablation on Î± parameter
â”‚   â”‚   â””â”€â”€ config.yaml
â”‚   â”‚
â”‚   â””â”€â”€ stage3/                  # Stage 3: DA-BOED
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ boed_optimization.py # BOED with DA-DPS
â”‚       â”œâ”€â”€ sequential_design.py # Sequential measurement selection
â”‚       â”œâ”€â”€ domain_generalization.py  # Cross-domain testing
â”‚       â”œâ”€â”€ real_data_validation.py   # Real imaging data
â”‚       â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ notebooks/                   # Jupyter notebooks for exploration
â”‚   â”œâ”€â”€ 01_disorder_theory_intro.ipynb
â”‚   â”œâ”€â”€ 02_ema_validation.ipynb
â”‚   â”œâ”€â”€ 03_ctrw_scheduling.ipynb
â”‚   â”œâ”€â”€ 04_da_boed_demo.ipynb
â”‚   â””â”€â”€ 05_results_visualization.ipynb
â”‚
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_diffusion.py
â”‚   â”œâ”€â”€ test_disorder.py
â”‚   â”œâ”€â”€ test_imaging.py
â”‚   â”œâ”€â”€ test_bayesian.py
â”‚   â””â”€â”€ test_utils.py
â”‚
â”œâ”€â”€ data/                        # Data directory (gitignored)
â”‚   â”œâ”€â”€ raw/                     # Raw datasets
â”‚   â”œâ”€â”€ processed/               # Processed datasets
â”‚   â”œâ”€â”€ pretrained/              # Pretrained diffusion models
â”‚   â””â”€â”€ results/                 # Experiment results
â”‚
â”œâ”€â”€ outputs/                     # Experiment outputs (gitignored)
â”‚   â”œâ”€â”€ stage1/
â”‚   â”œâ”€â”€ stage2/
â”‚   â””â”€â”€ stage3/
â”‚
â”œâ”€â”€ docs/                        # Documentation
â”‚   â”œâ”€â”€ api.md
â”‚   â”œâ”€â”€ methods.md
â”‚   â”œâ”€â”€ experiments.md
â”‚   â””â”€â”€ faq.md
â”‚
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ ci.yml               # GitHub Actions CI
```

---

## Installation Verification

After installation, verify everything works:

```python
# test_imports.py
import sys

print("Testing imports...")

# Core packages
import numpy as np
print(f"âœ“ NumPy {np.__version__}")

import torch
print(f"âœ“ PyTorch {torch.__version__}")
print(f"  - CUDA available: {torch.cuda.is_available()}")
print(f"  - Device: {torch.device('cuda' if torch.cuda.is_available() else 'cpu')}")

import scipy
print(f"âœ“ SciPy {scipy.__version__}")

# Deep Learning
from diffusers import DDIMScheduler, UNet2DModel
print("âœ“ Diffusers imported successfully")

import pytorch_lightning as pl
print(f"âœ“ PyTorch Lightning {pl.__version__}")

# Bayesian
import pymc as pm
print(f"âœ“ PyMC {pm.__version__}")

try:
    import jax
    print(f"âœ“ JAX {jax.__version__}")
except ImportError:
    print("âš  JAX not available (optional)")

# Visualization
import matplotlib.pyplot as plt
print(f"âœ“ Matplotlib {plt.matplotlib.__version__}")

import seaborn as sns
print(f"âœ“ Seaborn {sns.__version__}")

# Optimization
import cvxpy as cp
print(f"âœ“ CVXPY {cp.__version__}")

print("\nâœ… All critical imports successful!")
print(f"Python: {sys.version}")
```

Run with:
```bash
python test_imports.py
```

---

## GPU Setup (Optional but Recommended)

### Check GPU:
```python
import torch
print(torch.cuda.is_available())
print(torch.cuda.get_device_name(0))
print(torch.cuda.get_device_properties(0))
```

### Install CUDA Toolkit (if not using conda):
- Visit: https://developer.nvidia.com/cuda-downloads
- Follow installation instructions for your OS

### Install cuDNN (optional, for speedup):
- Download from: https://developer.nvidia.com/cudnn
- Follow Nvidia's installation guide

---

## Development Workflow

### 1. Code Quality Tools

```bash
# Format code with Black
black src/ experiments/ tests/

# Check code style
flake8 src/ --max-line-length=100

# Type checking
mypy src/

# Run linter
pylint src/
```

### 2. Testing

```bash
# Run all tests
pytest tests/ -v

# Run with coverage
pytest tests/ --cov=src --cov-report=html

# Run specific test
pytest tests/test_diffusion.py::test_dps_initialization -v

# Benchmark specific functions
pytest tests/test_diffusion.py --benchmark-only
```

### 3. Version Control

```bash
# Create feature branch
git checkout -b feature/stage1-da-dps

# Commit with conventional commits
git commit -m "feat(diffusion): implement disorder-averaged DPS"

# Push and create PR
git push origin feature/stage1-da-dps
```

---

## Common Issues and Solutions

### Issue 1: CUDA Out of Memory

```python
# Solution: Reduce batch size in config.yaml
batch_size: 4  # Instead of 32

# Or enable gradient checkpointing
model.gradient_checkpointing_enable()
```

### Issue 2: Import Errors

```bash
# Reinstall in editable mode
pip install -e .

# Or reinstall environment
conda env remove -n disorder-diffusion
conda env create -f environment.yml
```

### Issue 3: Dependency Conflicts

```bash
# Check dependency tree
pip tree

# Update all packages
conda update -n disorder-diffusion --all

# Or for pip
pip install --upgrade -r requirements.txt
```

### Issue 4: JAX/GPU Issues

```bash
# JAX might conflict with PyTorch on GPU
# Solution: Use CPU for JAX if needed
import jax
jax.config.update('jax_platform_name', 'cpu')
```

---

## Environment Variables

Create `.env` file in project root:

```bash
# .env
CUDA_VISIBLE_DEVICES=0  # GPU to use
PYTHONPATH=/path/to/disorder-diffusion:$PYTHONPATH
WANDB_PROJECT=disorder-diffusion-research
WANDB_ENTITY=your-username
LOG_LEVEL=INFO
```

Load with:
```bash
source .env
```

Or in Python:
```python
import os
from dotenv import load_dotenv
load_dotenv('.env')
```

---

## Computing Resources

### Recommended Hardware

**Stage 1 (DA-DPS)**:
- GPU: RTX 3070 or better (8GB VRAM sufficient)
- RAM: 32GB
- Storage: 100GB (models + datasets)
- Time: 1-2 weeks

**Stage 2 (CTRW-DPS)**:
- GPU: A100 or RTX 4090 (optimal)
- GPU: RTX 3080+ acceptable
- RAM: 64GB
- Storage: 200GB
- Time: 3-4 weeks

**Stage 3 (DA-BOED)**:
- GPU: Multi-GPU (2x A100 or 4x RTX 3090)
- RAM: 128GB
- Storage: 500GB
- Time: 8-12 weeks

### Cloud Options

**Google Colab** (Free/Paid):
```bash
# Install in Colab
!pip install -r requirements.txt
```

**AWS SageMaker** (Recommended for scale):
- Pre-configured PyTorch environments
- Easy multi-GPU/TPU scaling
- Integrated with notebooks

**Lambda Labs**:
- On-demand GPU rental
- Pay-per-hour
- Good for quick experiments

---

## Troubleshooting Conda

```bash
# Clear conda cache
conda clean --all

# Repair environment
conda install --force-reinstall -y -q --name disorder-diffusion --file requirements.txt

# See what's installed
conda list -n disorder-diffusion

# Export current environment
conda env export -n disorder-diffusion > environment_current.yml

# Remove and recreate
conda env remove -n disorder-diffusion
conda env create -f environment.yml
```

---

## Next Steps

1. **Install environment**: `conda env create -f environment.yml`
2. **Verify installation**: `python test_imports.py`
3. **Start with tutorials**: `jupyter lab` and open notebooks in `notebooks/`
4. **Run Stage 1 baseline**: `python experiments/stage1/evaluate_dps.py`

---

## Reference Documentation

- PyTorch: https://pytorch.org/docs/stable/
- Diffusers: https://huggingface.co/docs/diffusers/
- JAX: https://jax.readthedocs.io/
- PyMC: https://www.pymc.io/
- PyTorch Lightning: https://lightning.ai/

---

## Support and Questions

- Create GitHub issues for bugs
- Discussions tab for questions
- Email: your-email@institution.edu

Happy researching! ðŸš€
